{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# IMPACT in few lines of code",
   "id": "f5d4b13e73aeece6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T13:34:16.446248Z",
     "start_time": "2025-05-12T13:34:11.112251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IMPACT import utils, model\n",
    "\n",
    "# Set all the required parameters ---------------\n",
    "config = utils.generate_eval_config(dataset_name=\"math2\", learning_rate=0.02026, lambda_=1.2e-5, batch_size=2048, num_epochs=200,\n",
    "                                    valid_metric='mi_acc', pred_metrics=['mi_acc','rmse', 'mae'], profile_metrics=['doa', 'pc-er'], device = 'cpu')\n",
    "\n",
    "# Read the dataset and the metadata -------------\n",
    "train_data, valid_data, test_data = utils.prepare_dataset(config, i_fold=0)\n",
    "\n",
    "# Train the model --------------------------------\n",
    "algo = model.IMPACT(**config)\n",
    "algo.init_model(train_data, valid_data)\n",
    "algo.train(train_data, valid_data)\n",
    "\n",
    "# Test the model --------------------------------\n",
    "eval = algo.evaluate_predictions(test_data)\n",
    "print(\"rmse :\", eval[\"rmse\"])\n",
    "print(\"mae :\", eval[\"mae\"])\n",
    "eval = algo.evaluate_profiles(test_data)\n",
    "print(\"pc-er:\", eval[\"pc-er\"])\n",
    "print(\"doa:\", eval[\"doa\"])"
   ],
   "id": "9b7bfc2314c386ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 15\u001B[0m\n\u001B[1;32m     13\u001B[0m algo \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mIMPACT(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig)\n\u001B[1;32m     14\u001B[0m algo\u001B[38;5;241m.\u001B[39minit_model(train_data, valid_data)\n\u001B[0;32m---> 15\u001B[0m algo\u001B[38;5;241m.\u001B[39mtrain(train_data, valid_data)\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# Test the model --------------------------------\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28meval\u001B[39m \u001B[38;5;241m=\u001B[39m algo\u001B[38;5;241m.\u001B[39mevaluate_predictions(test_data)\n",
      "File \u001B[0;32m~/Programmation/IMPACT/IMPACT/model/abstract_model.py:170\u001B[0m, in \u001B[0;36mAbstractModel.train\u001B[0;34m(self, train_data, valid_data)\u001B[0m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m    169\u001B[0m \u001B[38;5;66;03m# Call the selected training method\u001B[39;00m\n\u001B[0;32m--> 170\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_method(train_loader, valid_loader, valid_data, optimizer, scheduler, scaler)\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdevice\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m    173\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_trained \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/Programmation/IMPACT/IMPACT/model/abstract_model.py:412\u001B[0m, in \u001B[0;36mAbstractModel._train_early_stopping_error\u001B[0;34m(self, train_loader, valid_loader, valid_data, optimizer, scheduler, scaler)\u001B[0m\n\u001B[1;32m    409\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m    411\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mamp\u001B[38;5;241m.\u001B[39mautocast(\u001B[38;5;28mstr\u001B[39m(device)):\n\u001B[0;32m--> 412\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_loss(user_ids, item_ids, dim_ids, labels)\n\u001B[1;32m    414\u001B[0m scaler\u001B[38;5;241m.\u001B[39mscale(loss)\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m    415\u001B[0m scaler\u001B[38;5;241m.\u001B[39mstep(optimizer)\n",
      "File \u001B[0;32m~/Programmation/IMPACT/IMPACT/model/IMPACT.py:472\u001B[0m, in \u001B[0;36mIMPACT._compute_loss\u001B[0;34m(self, users_id, items_id, concepts_id, labels)\u001B[0m\n\u001B[1;32m    468\u001B[0m beta \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.5\u001B[39m\n\u001B[1;32m    470\u001B[0m lambda_param \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlambda\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m--> 472\u001B[0m u_emb, im_emb_prime, i0_emb_prime, in_emb_prime, W_t \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mget_embeddings(users_id, items_id,\n\u001B[1;32m    473\u001B[0m                                                                                  concepts_id)\n\u001B[1;32m    475\u001B[0m L1, L2, L3 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss(u_emb\u001B[38;5;241m=\u001B[39mu_emb, im_emb_prime\u001B[38;5;241m=\u001B[39mim_emb_prime, i0_emb_prime\u001B[38;5;241m=\u001B[39mi0_emb_prime,\n\u001B[1;32m    476\u001B[0m                          in_emb_prime\u001B[38;5;241m=\u001B[39min_emb_prime, W_t\u001B[38;5;241m=\u001B[39mW_t,\n\u001B[1;32m    477\u001B[0m                          modalities_idx\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mir_idx[users_id, items_id],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    481\u001B[0m                          users_id\u001B[38;5;241m=\u001B[39musers_id, items_id\u001B[38;5;241m=\u001B[39mitems_id,\n\u001B[1;32m    482\u001B[0m                          concepts_id\u001B[38;5;241m=\u001B[39mconcepts_id, R\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mR, users_emb\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39musers_emb\u001B[38;5;241m.\u001B[39mweight)\n\u001B[1;32m    484\u001B[0m R \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mget_regularizer()\n",
      "File \u001B[0;32m~/Programmation/IMPACT/IMPACT/model/IMPACT.py:225\u001B[0m, in \u001B[0;36mIMPACTModel.get_embeddings\u001B[0;34m(self, user_ids, item_ids, concept_ids)\u001B[0m\n\u001B[1;32m    223\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_embeddings\u001B[39m(\u001B[38;5;28mself\u001B[39m, user_ids, item_ids, concept_ids):\n\u001B[1;32m    224\u001B[0m     \u001B[38;5;66;03m# User embeddings\u001B[39;00m\n\u001B[0;32m--> 225\u001B[0m     u_emb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39musers_emb(user_ids)  \u001B[38;5;66;03m# [batch_size, embedding_dim]\u001B[39;00m\n\u001B[1;32m    227\u001B[0m     \u001B[38;5;66;03m# Compute item-response indices\u001B[39;00m\n\u001B[1;32m    228\u001B[0m     im_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mim_idx[item_ids]  \u001B[38;5;66;03m# [batch_size, nb_mod]\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/cdbpr-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/cdbpr-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/anaconda3/envs/cdbpr-env/lib/python3.11/site-packages/torch/nn/modules/sparse.py:190\u001B[0m, in \u001B[0;36mEmbedding.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    189\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39membedding(\n\u001B[1;32m    191\u001B[0m         \u001B[38;5;28minput\u001B[39m,\n\u001B[1;32m    192\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight,\n\u001B[1;32m    193\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_idx,\n\u001B[1;32m    194\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_norm,\n\u001B[1;32m    195\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm_type,\n\u001B[1;32m    196\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscale_grad_by_freq,\n\u001B[1;32m    197\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparse,\n\u001B[1;32m    198\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/cdbpr-env/lib/python3.11/site-packages/torch/nn/functional.py:2551\u001B[0m, in \u001B[0;36membedding\u001B[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[0m\n\u001B[1;32m   2545\u001B[0m     \u001B[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001B[39;00m\n\u001B[1;32m   2546\u001B[0m     \u001B[38;5;66;03m# XXX: equivalent to\u001B[39;00m\n\u001B[1;32m   2547\u001B[0m     \u001B[38;5;66;03m# with torch.no_grad():\u001B[39;00m\n\u001B[1;32m   2548\u001B[0m     \u001B[38;5;66;03m#   torch.embedding_renorm_\u001B[39;00m\n\u001B[1;32m   2549\u001B[0m     \u001B[38;5;66;03m# remove once script supports set_grad_enabled\u001B[39;00m\n\u001B[1;32m   2550\u001B[0m     _no_grad_embedding_renorm_(weight, \u001B[38;5;28minput\u001B[39m, max_norm, norm_type)\n\u001B[0;32m-> 2551\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39membedding(weight, \u001B[38;5;28minput\u001B[39m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Saving and loading a model",
   "id": "ef6553afdc5d45dc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Saving a model",
   "id": "44cf5187150ffb7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "config = utils.generate_eval_config(dataset_name=\"postcovid\", learning_rate=0.02026, lambda_=1.2e-5, batch_size=2048, num_epochs=200,valid_metric='rmse', save_params=True)\n",
    "\n",
    "# Read the dataset and the metadata -------------\n",
    "train_data, valid_data, test_data = utils.prepare_dataset(config, i_fold=0)\n",
    "\n",
    "# Train the model --------------------------------\n",
    "algo = model.IMPACT(**config)\n",
    "algo.init_model(train_data, valid_data)\n",
    "algo.train(train_data, valid_data)"
   ],
   "id": "535450eb59c2c04d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading a model",
   "id": "59f5a5b9136a2e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "config = utils.generate_eval_config(dataset_name=\"postcovid\", learning_rate=0.02026, lambda_=1.2e-5, batch_size=2048, num_epochs=200, valid_metric='rmse', pred_metrics=['rmse', 'mae'], load_params=True, )\n",
    "\n",
    "# Read the dataset and the metadata -\n",
    "train_data, valid_data, test_data = utils.prepare_dataset(config, i_fold=0)\n",
    "\n",
    "# Train the model --------------------------------\n",
    "algo = model.IMPACT(**config)\n",
    "algo.init_model(train_data, valid_data)\n",
    "\n",
    "# Test the model --------------------------------\n",
    "eval_preds = algo.evaluate_predictions(test_data)"
   ],
   "id": "a97262f8c1bebc68"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
